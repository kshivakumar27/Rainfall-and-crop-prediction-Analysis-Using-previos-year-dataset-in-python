{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21122 entries, 0 to 21121\n",
      "Data columns (total 7 columns):\n",
      "State_Name       21122 non-null object\n",
      "District_Name    21122 non-null object\n",
      "Crop_Year        21122 non-null int64\n",
      "Season           21122 non-null object\n",
      "Crop             21122 non-null object\n",
      "Area             21122 non-null int64\n",
      "Production       21122 non-null float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/User/Desktop/kshi/crop/karcrop.csv\",sep=\",\")\n",
    "data = data.fillna(data.mean())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  State_Name District_Name  Crop_Year       Season          Crop   Area  \\\n",
      "0  Karnataka      BAGALKOT       1998  Kharif          Arhar/Tur   6154   \n",
      "1  Karnataka      BAGALKOT       1998  Kharif              Bajra  48855   \n",
      "2  Karnataka      BAGALKOT       1998  Kharif        Castor seed     71   \n",
      "3  Karnataka      BAGALKOT       1998  Kharif       Cotton(lint)  15225   \n",
      "4  Karnataka      BAGALKOT       1998  Kharif          Groundnut  16368   \n",
      "\n",
      "   Production  \n",
      "0      2602.0  \n",
      "1     52375.0  \n",
      "2        61.0  \n",
      "3     22129.0  \n",
      "4      7734.0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Crop_Year           Area    Production\n",
      "count  21122.000000   21122.000000  2.112200e+04\n",
      "mean    2006.199508    9606.577171  4.096161e+04\n",
      "std        4.989631   26295.617812  4.265591e+05\n",
      "min     1997.000000       1.000000  0.000000e+00\n",
      "25%     2002.000000     100.000000  1.160000e+02\n",
      "50%     2006.000000     839.500000  9.340000e+02\n",
      "75%     2011.000000    5419.750000  7.473750e+03\n",
      "max     2014.000000  510692.000000  1.802747e+07\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(groundtruth,prediction,title):        \n",
    "    N = 9\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.27       # the width of the bars\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    ax = fig.add_subplot(111)\n",
    "    rects1 = ax.bar(ind, groundtruth, width, color='r')\n",
    "    rects2 = ax.bar(ind+width, prediction, width, color='g')\n",
    "\n",
    "    ax.set_ylabel(\"Amount of rainfall\")\n",
    "    ax.set_xticks(ind+width)\n",
    "    ax.set_xticklabels( ('APR', 'MAY', 'JUN', 'JUL','AUG', 'SEP', 'OCT', 'NOV', 'DEC') )\n",
    "    ax.legend( (rects1[0], rects2[0]), ('Ground truth', 'Prediction') )\n",
    "\n",
    "#     autolabel(rects1)\n",
    "    for rect in rects1:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "    for rect in rects2:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "#     autolabel(rects2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperation of training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "division_data = np.asarray(data[['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',\n",
    "       'AUG', 'SEP', 'OCT', 'NOV', 'DEC']])\n",
    "\n",
    "X = None; y = None\n",
    "for i in range(division_data.shape[1]-3):\n",
    "    if X is None:\n",
    "        X = division_data[:, i:i+3]\n",
    "        y = division_data[:, i+3]\n",
    "    else:\n",
    "        X = np.concatenate((X, division_data[:, i:i+3]), axis=0)\n",
    "        y = np.concatenate((y, division_data[:, i+3]), axis=0)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.03, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[['DISTRICT','JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL','AUG', 'SEP', 'OCT', 'NOV', 'DEC']].loc[data['STATE_UT_NAME'] == 'KARNATAKA']\n",
    "kar = np.asarray(temp[['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL','AUG', 'SEP', 'OCT', 'NOV', 'DEC']].loc[temp['DISTRICT'] == 'KARNATAKA'])\n",
    "# print temp\n",
    "X_year = None; y_year = None\n",
    "for i in range(kar.shape[1]-3):\n",
    "    if X_year is None:\n",
    "        X_year = kar[:, i:i+3]\n",
    "        y_year = kar[:, i+3]\n",
    "    else:\n",
    "        X_year = np.concatenate((X_year, kar[:, i:i+3]), axis=0)\n",
    "        y_year = np.concatenate((y_year, kar[:, i+3]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.846026515406045\n",
      "[80.1359364  80.15166311 80.15166321 80.15168171 80.15166311 80.15166311\n",
      " 80.15166311 80.10518307 80.15166311]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# SVM model\n",
    "clf = SVR(gamma='auto', C=0.1, epsilon=0.2)\n",
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-10af87a798d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_year_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MEAN KARNATAKA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_year_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Standard deviation KARNATAKA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_year_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \"\"\"\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[1;32m--> 454\u001b[1;33m                         accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    548\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 550\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "y_year_pred = clf.predict(X_year)\n",
    "print(\"MEAN KARNATAKA\")\n",
    "print(np.mean(y_year),np.mean(y_year_pred))\n",
    "print(\"Standard deviation KARNATAKA\")\n",
    "print(np.sqrt(np.var(y_year)),np.sqrt(np.var(y_year_pred)))\n",
    "\n",
    "plot_graphs(y_year,y_year_pred,\"Prediction in KARNATAKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv1D, Flatten\n",
    "\n",
    "# NN model\n",
    "inputs = Input(shape=(3,1))\n",
    "x = Conv1D(64, 2, padding='same', activation='elu')(inputs)\n",
    "x = Conv1D(128, 2, padding='same', activation='elu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='elu')(x)\n",
    "x = Dense(64, activation='elu')(x)\n",
    "x = Dense(32, activation='elu')(x)\n",
    "x = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "model.compile(loss='mean_squared_error', optimizer='adamax', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=np.expand_dims(X_train, axis=2), y=y_train, batch_size=64, epochs=10, verbose=1, validation_split=0.1, shuffle=True)\n",
    "y_pred = model.predict(np.expand_dims(X_test, axis=2))\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(\"DISTRICT\").sum()['ANNUAL'].plot(figsize=(10,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['DISTRICT', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',\n",
    "       'AUG', 'SEP', 'OCT', 'NOV', 'DEC']].groupby(\"DISTRICT\").sum().plot(figsize=(10,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['DISTRICT', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',\n",
    "       'AUG', 'SEP', 'OCT', 'NOV', 'DEC']].groupby(\"DISTRICT\").mean().plot.barh(stacked=True,figsize=(5,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['DISTRICT', 'Jan-Feb', 'Mar-May',\n",
    "       'Jun-Sep', 'Oct-Dec']].groupby(\"DISTRICT\").sum().plot.barh(stacked=True,figsize=(5,7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.heatmap(data[['Jan-Feb','Mar-May','Jun-Sep','Oct-Dec','ANNUAL']].corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
